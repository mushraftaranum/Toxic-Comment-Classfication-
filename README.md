# ğŸ§  Toxic Comment Classification using Logistic Regression

This project aims to classify social media comments as toxic or non-toxic using machine learning. It serves as an early step toward identifying signs of depression or harmful content in online conversations.

## ğŸ” Project Overview

- Goal: Classify toxic comments using traditional machine learning models
- Dataset: Jigsaw Toxic Comment Classification Challenge (from Kaggle)
- Model Used: Logistic Regression
- Feature Extraction: TF-IDF Vectorization

## ğŸ—‚ï¸ Dataset

The dataset contains user comments labeled with different types of toxicity:

- toxic
- severe_toxic
- obscene
- threat
- insult
- identity_hate

For this project, we simplified the task to binary classification:  
ğŸ“Œ Toxic vs Non-Toxic

## ğŸ§ª Approach

1. Data Preprocessing:
   - Lowercasing
   - Removing punctuation, numbers, and stop words
   - Tokenization

2. Feature Engineering:
   - TF-IDF vectorization of cleaned text

3. Model Training:
   - Logistic Regression using scikit-learn

4. Evaluation:
   - Accuracy, Precision, Recall, F1 Score
   - Confusion Matrix
   - ROC Curve

## ğŸ“ˆ Results

- Achieved good performance in detecting toxic vs non-toxic comments.
- The model is lightweight and interpretable.
- Can be further improved with ensemble models or deep learning.

## ğŸ›  Tools & Technologies

- Python
- Google Colab
- scikit-learn
- pandas, numpy
- matplotlib, seaborn
- nltk for text preprocessing

## ğŸ“Œ Future Enhancements

- Use deep learning models like LSTM or BERT
- Integrate with social media APIs for real-time comment screening
- Build a web dashboard for live classification

## ğŸ“ Files in this Repo

- Toxic_Comment_Classification.ipynb â€” Colab notebook with full workflow
- README.md â€” You're reading it!
- (Optional) requirements.txt â€” List of required packages (if using a virtual environment)

## ğŸ¤ Acknowledgements

- [Kaggle Jigsaw Toxic Comment Dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)
- Inspired by the mission to build a safer online community

---

Made by Mushraf Taranum and Anisa Unisa
